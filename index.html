<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AIM 2025 Real-World RAW Denoising Challenge">
  <meta name="keywords" content="AIM, RAW Denoising">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AIM 2025 Real-World RAW Denoising Challenge</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./website/static/css/bulma.min.css">
  <link rel="stylesheet" href="./website/static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./website/static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./website/static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./website/static/css/index.css">
  <link rel="icon" href="./website/static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./website/static/js/fontawesome.all.min.js"></script>
  <script src="./website/static/js/bulma-carousel.min.js"></script>
  <script src="./website/static/js/bulma-slider.min.js"></script>
  <script src="./website/static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Real-World RAW Denoising Challenge<br> AIM 2025 Challenge</h1>
        <div class="is-size-5 publication-authors">
        Organized by <span class="author-block"><a href="https://ai.sony" target="_blank">Sony AI</a></span> and
        <span class="author-block"><a href="https://www.informatik.uni-wuerzburg.de/computervision/" target="_blank">Computer Vision Lab, University of Wurzburg</a></span>
        <br>
        </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://www.codabench.org/competitions/8529/" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-home"></i>
                  </span>
                  <span>Challenge Site & Data</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/SonyResearch/AIM2025_Denoise_Challenge/" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Starter Kit</span>
                  </a>
              </span>
            </div>


          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            Welcome to <a href="https://www.codabench.org/competitions/8529/" target="_blank">the 1st Edition of the RAW Image Denoising Challenge</a>, hosted at <a rel="license" href="https://www.cvlai.net/aim/2025/">Advances in Image Manipulation (AIM) workshop</a> in conjunction with ICCV 2025.
          </p>
        <p>This challenge aims to develop methods for predicting clean RAW images from their noisy counterparts in a <strong>self-supervised</strong> and <strong>camera-agnostic</strong> manner. Specifically, the proposed denoising solutions should eliminate reliance on the labor-intensive process of collecting paired noisy-clean datasets and demonstrate robust performance across diverse camera systems.
        </p>
        <p>
            To facilitate this, we have curated a comprehensive benchmark dataset encompassing multiple cameras and a variety of scenes, both indoor and outdoor, along with calibration data essential for noise modeling specific to each camera.
        </p>
        <p>
            Participants are encouraged to approach this challenge from two key perspectives.
        </p>
        <ul>
            <li><strong>Better noise modeling</strong>: novel usage of noise profiles from multiple cameras to enhance the noisy image synthesis pipeline for self-supervised learning.
            </li>
            <li>
            <strong>Better denoising methodologies</strong>: novel designs in network architectures, training strategies, or other techniques to achieve camera-agnostic RAW image denoising.
            </li>
        </ul>

<img src="./website/static/rawdenoise.png" alt="noise modelling"  width="1280" />
<p>
For the noise synthesis pipeline, we provide a baseline solution based on the method proposed <a href="https://arxiv.org/abs/2505.00045" target="_blank">here</a>. More details can be found at our <a href="https://github.com/SonyResearch/AIM2025_Denoise_Challenge" target="_blank">starter kit repo</a>.
</p>

<img src="./website/static/noise_synth_baseline.png" alt="noise modelling baseline"  width="1280" />

<p>
    The proposed solutions will be rigorously evaluated using both full-reference and no-reference image quality assessment (IQA) metrics, ensuring a comprehensive assessment of their effectiveness and generalizability.
</p>
<p>
The top-ranked participants will be awarded and invited to describe their solution to the associated the AIM at ICCV 2025. The results of the challenge will be published at AIM 2025 workshop (ICCV Proceedings).
</p>

        </div>
      </div>
    </div>

<section class="section" id="News">
  <div class="container is-max-desktop content">
    <h2 class="title">News</h2>
      [05/28/2025] Challenge starts. Website online. Dataset and starter kit released.
      <br>
      <br>
  </div>
</section>



<section class="section" id="Data">
  <div class="container is-max-desktop content">
      <h2 class="title">Data</h2>

      <img src="./website/static/example_shot.png" alt="dataset example"  width="1280" />
<h5>Training</h5>
<p>Clean images for training are unrestricted, allowing participants to utilize any dataset as long as its details are thoroughly documented in the final factsheet.</p>
<p>As a starting point, we recommend the clean images from the SID dataset (Sony split), which can be accessed <a href="https://cchen156.github.io/SID.html" target="_blank">here</a>.</p>

<h5>Testing</h5>
<p>Please register for the competition via <a href="https://www.codabench.org/competitions/8529/" target="_blank">codabench</a> to access the benchmark data and sample submission.</p>
<p>For benchmarking, we collected a dataset using four cameras: SonyA7R4, SonyA6700, SonyZVE10M2, and Canon70D.</p>
<p>To support the formulation of noise synthesis pipelines, we provide calibrated system gains and dark shading maps for each camera. The dataset includes two types of scenes:</p>
<ul>
    <li><strong>Paired Scene:</strong> Noisy images are captured under three ISO levels (800, 1600, and 3200) and three digital gains (10, 100, and 200). Each noisy image is paired with an aligned clean image obtained using a long exposure at the base ISO level.</li>
    <li><strong>In-the-Wild Scenes:</strong> Noisy images are collected under five ISO levels (800, 1250, 1600, 3200, and 6400) and various digital gains ranging from 10 to 200. These scenes represent real-world conditions, providing diverse and challenging scenarios for noise modeling and denoising.</li>
</ul>
<p>This benchmark dataset serves as a robust foundation for participants to develop and evaluate their camera-agnostic RAW denoising solutions.</p>
<p>More details on the dataset structure can be found in our <a href="https://github.com/SonyResearch/AIM2025_Denoise_Challenge" target="_blank">starter kit repo</a>.</p>
<p><strong>The dataset is for this challenge and research purposes only. Commercial use is not permitted.</strong></p>

  </div>
</section>



<section class="section" id="Eval">
  <div class="container is-max-desktop content">
    <h2 class="title">Evaluation</h2>


    <h5>Development phase</h5>
    <p>For Leaderboard, we rank participants based on PSNR &amp; SSIM on center-cropped (512, 512, 4) RGGB-packed Bayer RAW of the paired scenes.</li>
    </p>

    <h5>Final ranking (test) phase</h5>
    <p>We will manually verify the results of the top-ranked methods before releasing the final test-set ratings. The team ranking will be determined by ranking each metric:</p>
    <ul>
        <li>Full-reference metrics (PSNR, SSIM, and LPIPS) for paired scenes with aligned ground truth.</li>
        <li>No-reference metrics (ARNIQA and TOPIQ) for in-the-wild scenes.</li>
    </ul>
    <p>All evaluations will be measured on the full-resolution image. Specifically:</p>
    <ul>
        <li>PSNR &amp; SSIM on Bayer RAW.</li>
        <li>LPIPS, ARNIQA, and TOPIQ on sRGB with a simple ISP pipeline.</li>
    </ul>

    Additionally, we impose the following <strong>efficiency requirements</strong>:
    <ul>
        <li>Maximum 15 million parameters for the nerual network.</li>
        <li>MACs for the input shape of (1, 4, 512, 512) shall be less than 150 GMacs.</li>
        <li>Ensembles of multiple models are not allowed.</li>
    </ul>
    <p>More guidelines can be found in the <a href="https://github.com/SonyResearch/AIM2025_Denoise_Challenge/" target="_blank">starter kit repo</a>.</p>


  </div>
</section>


<section class="section" id="Award">
  <div class="container is-max-desktop content">
      <h2 class="title">Awards</h2>

<h5>Sony WH-1000XM5</h5>
      <img src="./website/static/WH-1000XM5_B_01.jpg" alt="sony wh-1000xm5"  width="512" />
<h5>Sony WF-1000XM5</h5>
      <img src="./website/static/WF-1000XM5_B_08.jpg" alt="sony wf-1000xm5"  width="512" />
  </div>
</section>


<section class="section" id="Organizers">
  <div class="container is-max-desktop content">
    <h2 class="title">Organizers</h2>
    <p>If you have questions, please contact us via the <a href="https://www.codabench.org/forums/8382/" target="_blank">challenge forum</a>.</p>
    <p><a href="https://sites.google.com/view/feiranlihomepage/home" target="_blank">Feiran Li</a> (Sony AI)</p>
    <p><a href="https://ddlee-cn.github.io/" target="_blank">Jiacheng Li</a> (Sony AI)</p>
    <p><a href="https://scholar.google.ca/citations?user=Gl-_XNAAAAAJ&hl=en" target="_blank">Beril Besbinar</a> (Sony AI)</p>
    <p><a href="https://scholar.google.com/citations?user=IzTZ1tAAAAAJ&hl=en" target="_blank">Vlad Hosu</a> (Sony AI)</p>
    <p><a href="https://ai.sony/people/Daisuke-Iso/" target="_blank">Daisuke Iso</a> (Sony AI)</p>
    <p><a href="https://mv-lab.github.io/" target="_blank">Marcos V. Conde</a> (University of Wuerzburg, CIDAUT AI)</p>
    <p><a href="https://www.cvlai.net/" target="_blank">Radu Timofte</a> (University of Wuerzburg)</p>
  </div>
</section>

<section class="section" id="Ref">
  <div class="container is-max-desktop content">
      <h2 class="title">References</h2>
        <p><a href="https://arxiv.org/abs/2505.00045" target="_blank">Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising</a>, in CVPR 2025</p>
        <p><a href="https://ieeexplore.ieee.org/document/10647496" target="_blank">Toward Efficient Deep Blind Raw Image Restoration</a>, in ICIP 2024</p>
        <p><a href="https://dl.acm.org/doi/10.1145/3503161.3548186" target="_blank">Learnability Enhancement for Low-light Raw Denoising: Where Paired Real Data Meets Noise Modeling</a>, in ACM MM 2022</p>
        <p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Rethinking_Noise_Synthesis_and_Modeling_in_Raw_Denoising_ICCV_2021_paper.pdf" target="_blank">Rethinking Noise Synthesis and Modeling in Raw Denoising</a>, in ICCV 2021</p>
        <p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_A_Physics-Based_Noise_Formation_Model_for_Extreme_Low-Light_Raw_Denoising_CVPR_2020_paper.pdf" target="_blank">A Physics-based Noise Formation Model for Extreme Low-light Raw Denoising</a>, in CVPR 2020</p>
  </div>
</section>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <a href="https://ai.sony/" target="_blank" rel="noopener noreferrer">
          <img src="
              https://research.sony/assets/images/sony_ai.svg" alt="Sony AI" width="250px">
          </a>
        </div>
        <div class="column has-text-centered">
          <a href="https://www.informatik.uni-wuerzburg.de/computervision/" target="_blank" rel="noopener noreferrer">
          <img src="https://www.cvlai.net/aim/2025/logos/JMU_CVL_logo.png" alt="Uni_Wuerzburg" width="150px">
          </a>
        </div>
        <div class="column has-text-centered">
          <a href="https://www.informatik.uni-wuerzburg.de/computervision/" target="_blank" rel="noopener noreferrer">
          <img src="https://www.cvlai.net/aim/2025/logos/Uni_Wuerzburg_logo.png" alt="Uni_Wuerzburg" width="250px">
          </a>
        </div>
        </div>
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>This website template is borrowed from <a rel="license" href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          <br>
          This challenge was organized by  <a href="https://ai.sony/">Sony AI</a> and the <a href="https://www.informatik.uni-wuerzburg.de/computervision/">Computer Vision Lab, University of Wurzburg</a>.
          <br>
          It is part of the <a href="https://www.cvlai.net/aim/2025/">Advances in Image Manipulation workshop</a> at ICCV 2025.
          </p>
        </div>
    </div>
  </div>
</footer>


</body>
</html>
